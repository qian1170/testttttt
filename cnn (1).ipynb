{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d73f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0507c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Choose the hyperparameters for training: \n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = Adam(model.parameters())\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(\"Device: \", device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "transform = Compose([Resize((224,224)), ToTensor()])\n",
    "\n",
    "# Prepare the datasets and loaders\n",
    "train_dataset = ImageFolder(root='waste/train', transform=transform)\n",
    "test_dataset = ImageFolder(root='waste/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106019ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.4673615046921938\n",
      "Epoch 2 loss: 0.40646668977338934\n",
      "Epoch 3 loss: 0.3611138430094246\n",
      "Epoch 4 loss: 0.31061740835901697\n",
      "Epoch 5 loss: 0.24676357447130146\n",
      "Epoch 6 loss: 0.1617218485423931\n",
      "Epoch 7 loss: 0.0919192249968479\n",
      "Epoch 8 loss: 0.0575358638897401\n",
      "Epoch 9 loss: 0.05424362372227076\n",
      "Epoch 10 loss: 0.029829617676116717\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # print statistics\n",
    "    print(f\"Epoch {epoch + 1} loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50b5ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 87.30600875447672%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Since we're testing the model we don't need to perform backprop\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Move the images and labels to the GPU if one is available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99710a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1336   65]\n",
      " [ 254  858]]\n",
      "Precision: 0.8797781908775405\n",
      "Recall: 0.8730600875447672\n",
      "F1 Score: 0.8711759740131764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# initialize lists to hold model outputs and targets\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# again, since we're testing the model we don't need to perform backprop\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # move the images and labels to the GPU if one is available\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # collect all model outputs and targets\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# compute precision, recall and f1 score\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa94c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'waste_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "350740b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4931ce32fe44da97e7194bbea7f480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "\n",
    "upload = FileUpload()\n",
    "upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aaf3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Take the first uploaded file\n",
    "uploaded_filename = next(iter(upload.value))\n",
    "\n",
    "# Get the file content\n",
    "content = upload.value[uploaded_filename]['content']\n",
    "\n",
    "# Convert the bytes to a PIL Image object\n",
    "image = Image.open(io.BytesIO(content))\n",
    "\n",
    "# Transform the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image_tensor = transform(image)\n",
    "\n",
    "# Add an extra batch dimension\n",
    "image_tensor = image_tensor.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ecc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted as Organic Waste\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Move the image tensor to the GPU if one is available\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    output = model(image_tensor)\n",
    "    _, prediction = torch.max(output.data, 1)\n",
    "\n",
    "if prediction.item()==1:\n",
    "    print('Predicted as Recycle Waste')\n",
    "else:\n",
    "    print('Predicted as Organic Waste')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a824c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
